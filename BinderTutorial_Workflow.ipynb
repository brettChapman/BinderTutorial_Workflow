{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Binder Tutorial Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>To begin: Click 'Run' on the toolbar (or shift-enter). Alternatively click Kernel, Restart and Run All.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow:** This is a typical metabolomics data analysis of a binary classification outcome. The main steps included are: data import, QC-based data cleaning, PCA visualisation to check QC precision, univariate statistics, multivariate analysis using PLS-DA (including model optimisation, model calculation and visualisation, and feature selection), and results export."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**: The dataset used for this tutorial has been previously published [REF] and deposited onto Metabolomics Workbench, http://www.metabolomicsworkbench.org, Project ID PR000699. The data can be accessed directly via its project DOI:10.21228/M8B10B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note for uploaded datasets**: We recommend using the same format as the Dataset provided. The file should be an excel spreadsheet, and contain a DATA and PEAK sheet. The DATA sheet should have an 'Idx', 'SampleID', and 'Class' column. The PEAK sheet should have an 'Idx', 'Name' and 'Label' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Import Packages/Modules](#1)\n",
    "2. [Load Data and Peak Sheet](#2)\n",
    "3. [Remove Peaks with RSD >= 20%](#3)\n",
    "4. [Quality Assessment using PCA (using Pooled QC samples)](#4)\n",
    "5. [Extract 2 groups for Dataset (GC vs HE)](#5)\n",
    "6. [Univariate statistics for 2 classes (GC vs. HE)](#6)\n",
    "7. [Extract X and Y matrix (+ split into a train / test set with stratification)](#7)\n",
    "8. [Determine number of components for PLS-DA model](#8)\n",
    "9. [Train and evaluate PLS-DA model](#9)\n",
    "10. [Perform a permutation test for PLS-DA model](#10)\n",
    "11. [Plot latent variable projections for PLS-DA model](#11)\n",
    "12. [Plot feature importance (Coefficient and VIP plot) for PLS-DA model](#12)\n",
    "13. [Test model with new data (using test set from section 7)](#13)\n",
    "14. [Export results to excel](#14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "<a id='1'></a>\n",
    "### 1. Import Packages/Modules\n",
    "We need to import modules to extend beyond the basic functionality of python:   \n",
    "- **NumPy**: a fundamental package for mathematical calculations  (http://www.numpy.org) \n",
    "- **pandas**: a fundamental package for importing and manipulating tables (https://pandas.pydata.org)\n",
    "- **BeakerX**: a package used specifically in this workflow to display pandas tables more interactively (http://beakerx.com)\n",
    "- **scikit-learn**: a fundamental package containing tools for data mining and analysis that is used directly in this workflow (with the train_test_split module to split data into train and test subsets (https://scikit-learn.org)\n",
    "- **cimcb_lite**: a core package by cimcb that wraps necessary tools for standard metabolomics data analysis workflows (https://github.com/cimcb/cimcb_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from beakerx.object import beakerx\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cimcb_lite \n",
    "\n",
    "beakerx.pandas_display_table() # by default display pandas tables as BeakerX interactive tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2. Load Data and Peak sheet\n",
    "\n",
    "We need to load the data and peak sheet:\n",
    "1. Set the home directory and file name of the excel spreadsheet\n",
    "2. Use cimcb_lite.utils.load_dataXL to load and validate the data sheet and peak sheet \n",
    "3. Using BeakerX we can view and check the loaded data table and peak table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = ''  # '' refers to the directory this notebook is in\n",
    "\n",
    "file = 'Gastric_NMR_upload.xlsx' # expects an excel spreadsheet\n",
    "\n",
    "DataTable, PeakTable = cimcb_lite.utils.load_dataXL(file, DataSheet='DATA', PeakSheet='PEAKS') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DataTable # View and check the DataTable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PeakTable # View and check PeakTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3. Remove Peaks with RSD >= 20%\n",
    "For this tutorial, lets set the RSD (relative standard deviation) cut-off to a typical value of 20%:\n",
    "1. Set RSD to the QC_RSD column in the PeakTable\n",
    "2. Only keep rows (peaks) in PeakTable with an RSD less than (<) 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSD = PeakTable.QC_RSD    \n",
    "PeakTable = PeakTable[RSD < 20]    \n",
    "\n",
    "print(\"Number of peaks remaining: {}\".format(len(PeakTable)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4. Quality Assessment using PCA (using Pooled QC samples)\n",
    "A PCA is perfomed on the dataset, and labelled by quality control (QC) or biological sample. Note, a typically dataset of high quality is expected to have QCs that cluster tightly compared to the biological samples in the PCA score plot:\n",
    "1. Extract X and Y (where Y refers to the QC vs. biological sample)\n",
    "2. Log transform, unit-scale and knn-impute missing values for X\n",
    "3. Plot using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract X and Y for check PCA\n",
    "peaklist = PeakTable.Name    # Set peaklist to the column that corresponds to the metabolite name in the DataTable\n",
    "Xqa = DataTable[peaklist]    # Pull out X matrix from DataTable using peaklist\n",
    "Yqa = DataTable.QC           # Pull out QC (for colour in PCA plot)\n",
    "\n",
    "# Log transform, unit-scale and knn-impute missing values for X.\n",
    "XLogqa = np.log10(Xqa)                                      # Log scale (base-10)\n",
    "XScaleqa = cimcb_lite.utils.scale(XLogqa, method='auto')    # methods include auto, pareto, vast, and level\n",
    "XXqa = cimcb_lite.utils.knnimpute(XScaleqa, k=3)            # missing value imputation (knn - 3 nearest neighbors)\n",
    "\n",
    "# Plot using PCA \n",
    "cimcb_lite.plot.pca(XXqa,\n",
    "                    pcx=1,                                             # pc for x-axis\n",
    "                    pcy=2,                                             # pc for y-axis\n",
    "                    group_label=Yqa,                                   # colour in PCA score plot\n",
    "                    sample_label=DataTable[['Order','SampleID']],      # labels for Hover in PCA score plot\n",
    "                    peak_label=PeakTable[['Name','Label','QC_RSD']])   # labels for Hover in PCA loadings plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### 5. Extract 2 groups for Dataset (GC vs HE)  \n",
    "\n",
    "Lets create a new datable (DataTable2), and only keep samples where the ClassFULL column is either 'GC' or 'HE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTable2 = DataTable[(DataTable.ClassFULL == \"GC\") | (DataTable.ClassFULL == \"HE\")]\n",
    "\n",
    "print(\"Number of samples = {}\".format(len(DataTable2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "### 6. Univariate statistics for 2 classes (GC vs. HE)\n",
    "Generate a Statistics Table (StatsTable) with univariate statistics for 'GC' vs. 'HE' where 'GC' is the positive class.\n",
    "- if parametric=True, include Mean + T-Test\n",
    "- if parametric=False, include Median + Mannâ€“Whitney U Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "StatsTable = cimcb_lite.utils.univariate_2class(DataTable2,\n",
    "                                                PeakTable,\n",
    "                                                group='ClassFULL',     # Column used to determine the groups\n",
    "                                                posclass='GC',         # Value of posclass in the group column\n",
    "                                                parametric=True)       # Set parametric = True or False\n",
    "\n",
    "StatsTable    # View and check PeakTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "### 7. Extract X and Y matrix (+ split into a train / test set with stratification)\n",
    "Extract the X and Y matrix for 'GC' vs. 'HE', including a split (80/20) for a training set and a validation set.\n",
    "1. Extract Y using the ClassFULL column in DataTable2\n",
    "2. Convert Y to binary, where 1='GC' and 0='HE'\n",
    "3. Split the DataTable2, and Y into the training set and validation set\n",
    "3. Pull of X matrix using peaklist ('Name' column in PeakTable)\n",
    "4. Log transform, unit-scale and knn-impute missing values for X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and Convert Y to binary\n",
    "Y = DataTable2.ClassFULL                          # Column that corresponds to Y class (should be 2 groups)\n",
    "pos_class = \"GC\"                                  # Name of value in Y that corresponds to the positive class\n",
    "Y = [1 if i == pos_class else 0 for i in Y]       # Change Y to binary (1 = pos_class)\n",
    "Y = np.array(Y)                                   # convert list to an array (best practice to use numpy arrays)\n",
    "\n",
    "# Split DataTable2 and Y into train and test (with stratification)\n",
    "DataTrain, DataTest, Ytrain, Ytest = train_test_split(DataTable2, Y, test_size=0.2, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X matrix using 'Name' column in PeakTable\n",
    "peaklist = PeakTable.Name             # Set peaklist to the column that corresponds to the peak name in the DataTable\n",
    "Xtrain = DataTrain[peaklist]          # Pull out X matrix from DataTable using peaklist\n",
    "\n",
    "# Log transform, unit-scale and knn-impute missing values for X.\n",
    "Xtrain_log = np.log(Xtrain)                                           # Log scale (base-10)\n",
    "Xtrain_scale  = cimcb_lite.utils.scale(Xtrain_log, method='auto')     # methods include auto, pareto, vast, and level\n",
    "XXtrain = cimcb_lite.utils.knnimpute(Xtrain_scale, k=3)               # missing value imputation (knn = 3)\n",
    "\n",
    "print(\"XXtrain = {} rows & {} columns\".format(*XXtrain.shape))\n",
    "print(\"Ytrain = {} rows, with {} postive cases.\".format(len(Ytrain),sum(Ytrain)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8'></a>\n",
    "### 8. Determine number of components for PLS-DA model\n",
    "The optimal number of components for the PLS-DA model is where R2 is greatest, while the difference between R2 and Q2 is minimal [better way to phrase this? cite?]. To determine this, we use kfold cross-validation (stratified) and then analyse the R2/Q2 plots:\n",
    "\n",
    "1. Set param_dict to the number of components to check\n",
    "2. Run the cross_val module\n",
    "3. Use the plot function to determine the optimal n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set parameter values to search\n",
    "param_dict = {'n_components': [1, 2, 3, 4, 5, 6]}\n",
    "\n",
    "\n",
    "# initalise cross_val kfold (stratified) \n",
    "cv = cimcb_lite.cross_val.kfold(model=cimcb_lite.model.PLS_SIMPLS,      # model; we are using the PLS_SIMPLS model\n",
    "                                X=XXtrain,                              # X; XXtrain from section 7\n",
    "                                Y=Ytrain,                               # Y; Ytrain from section 7\n",
    "                                param_dict=param_dict,                  # param_dict; parameter-space \n",
    "                                folds=5,                                # folds; for the number of splits (k-fold)\n",
    "                                bootnum=100)                            # bootnum; for the Confidence Intervals\n",
    "cv.run()  \n",
    "\n",
    "# plot\n",
    "cv.plot()  # Based on these plots, we will set the n_components = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='9'></a>\n",
    "### 9. Train and evaluate PLS-DA model\n",
    "\n",
    "In section 8, we determined the optimal number of components is 2. So lets set n_components=2, and evaluate the model.\n",
    "1. Set modelPLS as the PLS_SIMPLS model with n_components=2\n",
    "2. Train the modelPLS with X=XXTrain, Y=Ytrain\n",
    "3. Evaluate the modelPLS (lets set the specificity=0.8 or alternatively set the cutoffscore to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initalise the model with n_components = 2\n",
    "modelPLS = cimcb_lite.model.PLS_SIMPLS(n_components=2)\n",
    "\n",
    "# Train the model \n",
    "modelPLS.train(XXtrain,Ytrain)\n",
    "\n",
    "# Evaluate the model... remove the # \n",
    "#modelPLS.evaluate(cutoffscore=0.5)  \n",
    "modelPLS.evaluate(specificity=0.8)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='10'></a>\n",
    "### 10. Perform a permutation test for PLS-DA model\n",
    "The permutation test can be used to assess the validity of the model. The permutation test is where the data is permuted or 'shuffled', and a new model is then trained and tested. A reliable model is where the R2 and Q2 generated from these models (with randomised data) is much lower than the original model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelPLS.permutation_test(nperm=100) #nperm refers to the number of permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11'></a>\n",
    "### 11. Plot latent variable projections for PLS-DA model\n",
    "This grid contains 3 types of plots:\n",
    "- **Scatterplot**: LVx vs. LVy with the line indicating the direction of maximum discrimination\n",
    "- **ROC plot**: LVx / LVy with the maximum discrimination\n",
    "- **Distribution plot**: Each LV (with group 0 and group 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLS.plot_projections(label=DataTrain[['Idx','SampleID']], size=12) # size changes circle size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='12'></a>\n",
    "### 12. Plot feature importance (Coefficient plot and VIP) for PLS-DA model\n",
    "This plots the Coefficient and VIP plots (with bootstrapped confidence intervals), and then adds those metrics to a Peaksheet. \n",
    "\n",
    "1. Calculate the bootstrapped confidence intervals \n",
    "2. Plot the feature importance plots, and return a new Peaksheet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the bootstrapped confidence intervals \n",
    "modelPLS.calc_bootci(type='perc', bootnum=1000)\n",
    "\n",
    "# Plot the feature importance plots, and return a new Peaksheet \n",
    "Peaksheet = modelPLS.plot_featureimportance(PeakTable,\n",
    "                                            peaklist,\n",
    "                                            ylabel='Label', # change ylabel to 'Name' \n",
    "                                            sort=True)      # change sort to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='13'></a>\n",
    "### 13. Test model with new data (using test set from section 7)\n",
    "Now lets test the model that was previously trained using a new dataset. In this example, we will use the test set (DataTest, Ytest) from the train_test_split in section 7. Alternatively, a new dataset could be loaded in and used.\n",
    "\n",
    "1. Get mu and sigma from the training dataset to use for the Xtest scaling\n",
    "2. Pull of Xtest from DataTest using peaklist ('Name' column in PeakTable)\n",
    "3. Log transform, unit-scale and knn-impute missing values for Xtest\n",
    "4. Calculate Ypredicted score using modelPLS.test\n",
    "5. Evaluate Ypred against Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mu and sigma from the training dataset to use for the Xtest scaling\n",
    "mu, sigma  = cimcb_lite.utils.scale(Xtrain_log, return_mu_sigma=True) \n",
    "\n",
    "# Pull of Xtest from DataTest using peaklist ('Name' column in PeakTable)\n",
    "peaklist = PeakTable.Name \n",
    "Xtest = DataTest[peaklist].values\n",
    "\n",
    "# Log transform, unit-scale and knn-impute missing values for Xtest\n",
    "Xtest_log = np.log(Xtest)\n",
    "Xtest_scale  = cimcb_lite.utils.scale(Xtest_log, method='auto', mu=mu, sigma=sigma) \n",
    "XXtest = cimcb_lite.utils.knnimpute(Xtest_scale, k=3)\n",
    "\n",
    "# Calculate Ypredicted score using modelPLS.test\n",
    "Ypred = modelPLS.test(XXtest)\n",
    "\n",
    "# Evaluate Ypred against Ytest\n",
    "evals = [Ytest, Ypred]\n",
    "modelPLS.evaluate(evals, specificity=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='14'></a>\n",
    "### 14. Export results to excel\n",
    "Finally, we will save a Datasheet for the test data (with Ypred), and export the StatsTable, Datasheet, and Peaksheet as an excel file (\"modelPLS.xlsx\"):\n",
    "1. Save DataSheet as 'Idx', 'SampleID', and 'Class' from DataTest\n",
    "2. Add 'Ypred' to Datasheet\n",
    "3. Create an empty excel file\n",
    "4. Add each table to the excel file (StatsTable, Datasheet, and Peaksheet)\n",
    "5. Close the excel writer and output the excel file\n",
    "\n",
    "<font color='red'>**Note:** To download the excel file; click File, open, checklist box (next to the file) and download.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataSheet as 'Idx', 'SampleID', and 'Class' from DataTest\n",
    "Datasheet = DataTest[[\"Idx\", \"SampleID\", \"Class\"]].copy() \n",
    "\n",
    "# Add 'Ypred' to Datasheet\n",
    "Datasheet['Ypred'] = Ypred \n",
    " \n",
    "Datasheet # View and check the DataTable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty excel file\n",
    "writer = pd.ExcelWriter(\"modelPLS.xlsx\")     # name of the excel spreadsheet\n",
    "\n",
    "# Add each table to the excel file (StatsTable, Datasheet, and Peaksheet) \n",
    "StatsTable.to_excel(writer, sheet_name='StatsTable', index=False)      # sheet_name=name of the sheet in excel \n",
    "Datasheet.to_excel(writer, sheet_name='Datasheet', index=False)        # index=False removed the 'index' column)\n",
    "Peaksheet.to_excel(writer, sheet_name='Peaksheet', index=False)\n",
    "\n",
    "# Close the excel writer and output the excel file\n",
    "writer.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "338px",
    "width": "315px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "184px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
