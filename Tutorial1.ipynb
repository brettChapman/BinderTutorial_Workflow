{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo_text.png\" width=\"250px\" align=\"right\">\n",
    "\n",
    "# Binder Jupyter Tutorial: Metabolomics Data Analysis Workflow\n",
    "\n",
    "#### <font size=\"3\" color='red'>To begin: Click anywhere in this cell and press 'Run' on the menu bar.<br> The next cell in the notebook is then automatically highlighted. Press 'Run' again.<br>Repeat this process until the end of the notebook.<br> Alternatively click 'Kernel' followed by 'Restart and Run All'.<br> NOTE: Some code cells may take several seconds to execute, please be patient.<br></font>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:5px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "## 1. Import Packages/Modules\n",
    "The first code cell of this tutorial (below this text box) imports packages and modules into the Jupter environment to extend our capability beyond the basic functionality of python. <br>\n",
    "\n",
    "**Run the cell by clicking anywhere in the cell and then clicking \"Run\" in the Menu.** <br>\n",
    "When sucessfully executed the cell will print \"All packages successfully loaded\" in the notebook below the cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from beakerx.object import beakerx\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cimcb_lite as cb\n",
    "beakerx.pandas_display_table() # by default display pandas tables as BeakerX interactive tables\n",
    "print('All packages successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:5px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "## 2. Load Data and Peak sheet\n",
    "The next code cell loads the *Data* and *Peak* sheets from an Excel file:\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = ''  # '' Use a blank home folder location when running in Binder\n",
    "# home = '/Users/davidbroadhurst/Documents/DATA/JupyterTutorial/' #OSX home example\n",
    "# home = '\\Users\\davidbroadhurst\\Documents\\DATA\\JupyterTutorial\\' #Miscrosoft Windows home example\n",
    "\n",
    "file = 'GastricCancer_NMR.xlsx' # expects an excel spreadsheet\n",
    "\n",
    "DataTable,PeakTable = cb.utils.load_dataXL(file, DataSheet='Data', PeakSheet='Peak') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:5px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "### Display the Data sheet\n",
    "\n",
    "Using the <b>BeakerX</b> package we can interactively view and check the imported Data table simply by calling the function <span style=\"font-family: monaco; font-size: 14px; background-color:white;\">display(DataTable)</span><br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(DataTable) # View and check the DataTable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:5px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "### Display the Peak sheet\n",
    "Using the <b>BeakerX</b> package we can interactively view and check the imported Peak table  simply by calling the function <span style=\"font-family: monaco; font-size: 14px; background-color:white;\">display(PeakTable)</span><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(PeakTable) # View and check PeakTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "## 3. Data Cleaning\n",
    "\n",
    "It is good practice to assess the quality of your data, and remove (clean out) any poorly measured metabolites. We have decided to only keep any metabolites with a QC-RSD less than 20% and with a percentage missing values less than 10%.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean peak table \n",
    "\n",
    "RSD = PeakTable['QC_RSD']  \n",
    "PercMiss = PeakTable['Perc_missing']  \n",
    "PeakTableClean = PeakTable[(RSD < 20) & (PercMiss < 10)]   \n",
    "\n",
    "print(\"Number of peaks remaining: {}\".format(len(PeakTableClean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "## 4. PCA - Quality Assesment\n",
    "\n",
    "To provide a multivariate assesment of the quality of the cleaned data set it is good practice perform a simple principal components analysis (PCA; after suitable tranforming & scaling) labelled by quality control (QC) or biological sample (Sample). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and scale the metabolite data from the DataTable \n",
    "\n",
    "peaklist = PeakTableClean['Name']                   # Set peaklist to the metabolite names in the DataTableClean\n",
    "X = DataTable[peaklist]                             # Extract X matrix from DataTable using peaklist\n",
    "Xlog = np.log10(X)                                  # Log scale (base-10)\n",
    "Xscale = cb.utils.scale(Xlog, method='auto')        # methods include auto, pareto, vast, and level\n",
    "Xknn = cb.utils.knnimpute(Xscale, k=3)              # missing value imputation (knn - 3 nearest neighbors)\n",
    "\n",
    "# Perform PCA analysis \n",
    "\n",
    "cb.plot.pca(Xknn,\n",
    "            pcx=1,                                                  # pc for x-axis\n",
    "            pcy=2,                                                  # pc for y-axis\n",
    "            group_label=DataTable['SampleType'],                    # colour in PCA score plot\n",
    "            sample_label=DataTable[['Idx','SampleType']],           # labels for Hover in PCA score plot\n",
    "            peak_label=PeakTableClean[['Name','Label']])            # labels for Hover in PCA loadings plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "## 5. Univariate Statistics for the comparison of Gastric Cancer (GC) vs Healthy Controls (HE)  \n",
    "\n",
    "Here we create  a simple statistical comparison table comparing the means of the GC vs HE patients groups.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subset of Data for statistical comparison\n",
    "DataTable2 = DataTable[(DataTable.Class == \"GC\") | (DataTable.Class == \"HE\")]\n",
    "pos_outcome = \"GC\" \n",
    "\n",
    "# Calculate basic statistics and create a statistics table.\n",
    "StatsTable = cb.utils.univariate_2class(DataTable2,\n",
    "                                        PeakTableClean,\n",
    "                                        group='Class',                # Column used to determine the groups\n",
    "                                        posclass=pos_outcome,         # Value of posclass in the group column\n",
    "                                        parametric=True)              # Set parametric = True or False\n",
    "\n",
    "# View and check StatsTable\n",
    "display(StatsTable)\n",
    "\n",
    "# Save StatsTable to Excel\n",
    "writer = pd.ExcelWriter(\"Stats.xlsx\")\n",
    "StatsTable.to_excel(writer, sheet_name='StatsTable', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "## 6. Machine Learning\n",
    "\n",
    "The remainder of the tutorial will focus on implementing a simple 2-class Partial Least Squares Discriminant Analysis (PLS-DA) model.\n",
    "\n",
    "### 6.1 Spliting the metabolimics data into a Training and Test sets.\n",
    "\n",
    "<p style=\"text-align: justify\"> The code cell below first selects a subset of data for a 2-class comparsion (GC vs HE), and then splits the resulting Data table into DataTrain and DataTest tables, such that number of DataTest samples is 25% of the the total samples. In order to ensure that the random sample-split is stratified we need to supply a binary vector indicating stratifiaction group membership.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subset of Data for the PLS-DA model\n",
    "DataTable2 = DataTable[(DataTable.Class == \"GC\") | (DataTable.Class == \"HE\")]\n",
    "\n",
    "# Create a Binary Y vector for stratifiying the samples\n",
    "Outcomes = DataTable2['Class']                                  # Column that corresponds to Y class (should be 2 groups)\n",
    "Y = [1 if outcome == 'GC' else 0 for outcome in Outcomes]       # Change Y into binary (GC = 1, HE = 0)  \n",
    "Y = np.array(Y)                                                 # convert boolean list into to a numpy array\n",
    "\n",
    "# Split DataTable2 and Y into train and test (with stratification)\n",
    "DataTrain, DataTest, Ytrain, Ytest = train_test_split(DataTable2, Y, test_size=0.25, stratify=Y)\n",
    "\n",
    "print(\"DataTrain = {} samples with {} postive cases.\".format(len(Ytrain),sum(Ytrain)))\n",
    "print(\"DataTest = {} samples with {} postive cases.\".format(len(Ytest),sum(Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "  \n",
    "### 6.2. Determine number of components for PLS-DA model\n",
    "\n",
    "For this code cell, we first extract and scale the X data in the same way as Section 4.\n",
    "We then choose the optimal model structure by examining the output plot. <br>\n",
    "In this example the <b>optimal model uses 2 components</b>. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract and scale the metabolite data from the DataTable\n",
    "peaklist = PeakTableClean['Name']                           # Set peaklist to the metabolite names in the DataTableClean\n",
    "XT = DataTrain[peaklist]                                    # Extract X matrix from DataTrain using peaklist\n",
    "XTlog = np.log(XT)                                          # Log scale (base-10)\n",
    "XTscale = cb.utils.scale(XTlog, method='auto')              # methods include auto, pareto, vast, and level\n",
    "XTknn = cb.utils.knnimpute(XTscale, k=3)                    # missing value imputation (knn - 3 nearest neighbors)\n",
    "\n",
    "# Set the number of latent variables to search\n",
    "param_dict = {'n_components': [1,2,3,4,5,6]}\n",
    "\n",
    "# initalise cross_val kfold (stratified) \n",
    "cv = cb.cross_val.kfold(model=cb.model.PLS_SIMPLS,                      # model; we are using the PLS_SIMPLS model\n",
    "                                X=XTknn,                                 \n",
    "                                Y=Ytrain,                               \n",
    "                                param_dict=param_dict,                   \n",
    "                                folds=5,                                # folds; for the number of splits (k-fold)\n",
    "                                bootnum=100)                            # num bootstraps for the Confidence Intervals\n",
    "\n",
    "# run the cross validation\n",
    "cv.run()  \n",
    "\n",
    "# plot cross validation statistics\n",
    "cv.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "### 6.3 Train and evaluate PLS-DA model\n",
    "\n",
    "In Section 6.2 we determined the optimal number of components for this exampl data set is 2. So create a PLS-DA model with 2 components and evaluate the predictive ability. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initalise the model with n_components = 2\n",
    "modelPLS = cb.model.PLS_SIMPLS(n_components=2)\n",
    "\n",
    "# Train the model \n",
    "modelPLS.train(XTknn,Ytrain)\n",
    "\n",
    "# Evaluate the model \n",
    "modelPLS.evaluate(specificity=0.9)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "### 10. Perform a permutation test for PLS-DA model\n",
    "The permutation test can be used to assess the validity of the model. The permutation test is where the data is permuted or 'shuffled', and a new model is then trained and tested. A reliable model is where the R2 and Q2 generated from these models (with randomised data) is much lower than the original model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelPLS.permutation_test(nperm=100) #nperm refers to the number of permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.5'></a>\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "### 11. Plot latent variable projections for PLS-DA model\n",
    "This grid contains 3 types of plots:\n",
    "- **Scatterplot**: LVx vs. LVy with the line indicating the direction of maximum discrimination\n",
    "- **ROC plot**: LVx / LVy with the maximum discrimination\n",
    "- **Distribution plot**: Each LV (with group 0 and group 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLS.plot_projections(label=DataTrain[['Idx','SampleID']], size=12) # size changes circle size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.6'></a>\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "### 12. Plot feature importance (Coefficient plot and VIP) for PLS-DA model\n",
    "This plots the Coefficient and VIP plots (with bootstrapped confidence intervals), and then adds those metrics to a Peaksheet. \n",
    "\n",
    "1. Calculate the bootstrapped confidence intervals \n",
    "2. Plot the feature importance plots, and return a new Peaksheet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the bootstrapped confidence intervals \n",
    "modelPLS.calc_bootci(type='bca', bootnum=200) # decrease bootnum if it is taking too long\n",
    "\n",
    "# Plot the feature importance plots, and return a new Peaksheet \n",
    "Peaksheet = modelPLS.plot_featureimportance(PeakTableClean,\n",
    "                                            peaklist,\n",
    "                                            ylabel='Label', # change ylabel to 'Name' \n",
    "                                            sort=False)      # change sort to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.7'></a>\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "### 13. Test model with new data (using test set from section 7)\n",
    "Now lets test the model that was previously trained using a new dataset. In this example, we will use the test set (DataTest, Ytest) from the train_test_split in section 7. Alternatively, a new dataset could be loaded in and used.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get mu and sigma from the training dataset to use for the Xtest scaling\n",
    "mu, sigma  = cb.utils.scale(XTlog, return_mu_sigma=True) \n",
    "\n",
    "# Pull of Xtest from DataTest using peaklist ('Name' column in PeakTable)\n",
    "peaklist = PeakTableClean.Name \n",
    "XV = DataTest[peaklist].values\n",
    "\n",
    "# Log transform, unit-scale and knn-impute missing values for Xtest\n",
    "XVlog = np.log(XV)\n",
    "XVscale  = cb.utils.scale(XVlog, method='auto', mu=mu, sigma=sigma) \n",
    "XVknn = cb.utils.knnimpute(XVscale, k=3)\n",
    "\n",
    "# Calculate Ypredicted score using modelPLS.test\n",
    "YVpred = modelPLS.test(XVknn)\n",
    "\n",
    "# Evaluate Ypred against Ytest\n",
    "evals = [Ytest, YVpred]    # alternative formats: (Ytest, Ypred) or np.array([Ytest, Ypred])\n",
    "#modelPLS.evaluate(evals, specificity=0.9)\n",
    "modelPLS.evaluate(evals, cutoffscore=0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.8'></a>\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "### 14. Export results to excel\n",
    "Finally, we will save a Datasheet for the test data (with Ypred), and export the StatsTable, Datasheet, and Peaksheet as an excel file (\"modelPLS.xlsx\")</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataSheet as 'Idx', 'SampleID', and 'Class' from DataTest\n",
    "Datasheet = DataTest[[\"Idx\", \"SampleID\", \"Class\"]].copy() \n",
    "\n",
    "# Add 'Ypred' to Datasheet\n",
    "Datasheet['Ypred'] = YVpred \n",
    " \n",
    "Datasheet # View and check the DataTable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty excel file\n",
    "writer = pd.ExcelWriter(\"modelPLS.xlsx\")     # name of the excel spreadsheet\n",
    "\n",
    "Datasheet.to_excel(writer, sheet_name='Datasheet', index=False)\n",
    "Peaksheet.to_excel(writer, sheet_name='Peaksheet', index=False)\n",
    "\n",
    "# Close the excel writer and output the excel file\n",
    "writer.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "338px",
    "width": "315px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "184px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
